{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip\n",
    "import pickle\n",
    "import functools\n",
    "import nevergrad as ng\n",
    "import os\n",
    "import dynamiqs as dq\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "dq.set_device('cpu')\n",
    "\n",
    "from CoupledQuantumSystems.drive import DriveTerm\n",
    "from CoupledQuantumSystems.IFQ import gfIFQ\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def square_pulse_with_rise_fall_jnp(t,\n",
    "                                args = {}):\n",
    "    \n",
    "    w_d = args['w_d']\n",
    "    amp = args['amp']\n",
    "    t_start = args.get('t_start', 0)  # Default start time is 0\n",
    "    t_rise = args.get('t_rise', 1e-10)  # Default rise time is 0 for no rise\n",
    "    t_square = args.get('t_square', 0)  # Duration of constant amplitude\n",
    "\n",
    "    def cos_modulation():\n",
    "        return 2 * jnp.pi * amp * jnp.cos(w_d * 2 * jnp.pi * t)\n",
    "    \n",
    "    t_fall_start = t_start + t_rise + t_square  # Start of fall\n",
    "    t_end = t_fall_start + t_rise  # End of the pulse\n",
    "\n",
    "    before_pulse_start = jnp.less(t, t_start)\n",
    "    during_rise_segment = jnp.logical_and(jnp.greater(t_rise, 0), jnp.logical_and(jnp.greater_equal(t, t_start), jnp.less_equal(t, t_start + t_rise)))\n",
    "    constant_amplitude_segment = jnp.logical_and(jnp.greater(t, t_start + t_rise), jnp.less_equal(t, t_fall_start))\n",
    "    during_fall_segment = jnp.logical_and(jnp.greater(t_rise, 0), jnp.logical_and(jnp.greater(t, t_fall_start), jnp.less_equal(t, t_end)))\n",
    "\n",
    "    return jnp.where(before_pulse_start, 0,\n",
    "                    jnp.where(during_rise_segment, jnp.sin(jnp.pi * (t - t_start) / (2 * t_rise)) ** 2 * cos_modulation(),\n",
    "                            jnp.where(constant_amplitude_segment, cos_modulation(),\n",
    "                                        jnp.where(during_fall_segment, jnp.sin(jnp.pi * (t_end - t) / (2 * t_rise)) ** 2 * cos_modulation(), 0))))\n",
    "\n",
    "solver = dq.solver.Dopri8(\n",
    "                    rtol= 1e-06,\n",
    "                    atol= 1e-06,\n",
    "                    safety_factor= 0.6,\n",
    "                    min_factor= 0.1,\n",
    "                    max_factor = 4.0,\n",
    "                    max_steps = int(1e4*1000),\n",
    "                )\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Define your parameters and objects\n",
    "# -------------------------------\n",
    "EJ = 3\n",
    "EJoverEC = 6\n",
    "EJoverEL = 25\n",
    "EC = EJ / EJoverEC\n",
    "EL = EJ / EJoverEL\n",
    "\n",
    "qbt = gfIFQ(EJ=EJ, EC=EC, EL=EL, flux=0, truncated_dim=20)\n",
    "\n",
    "driven_op=qutip.Qobj(qbt.fluxonium.n_operator(energy_esys=True))\n",
    "\n",
    "e_ops = [\n",
    "    qutip.basis(qbt.truncated_dim, i) * qutip.basis(qbt.truncated_dim, i).dag()\n",
    "    for i in range(10)\n",
    "]\n",
    "\n",
    "element = np.abs(\n",
    "    qbt.fluxonium.matrixelement_table(\"n_operator\", evals_count=3)[1, 2]\n",
    ")\n",
    "freq = (qbt.fluxonium.eigenvals()[2] - qbt.fluxonium.eigenvals()[1]) * 2 * np.pi\n",
    "init_wd = qbt.fluxonium.eigenvals()[2] - qbt.fluxonium.eigenvals()[1]\n",
    "\n",
    "# -------------------------------\n",
    "# Objective function\n",
    "# -------------------------------\n",
    "def objective(t_tot, amp, w_d,ramp):\n",
    "    tlist = jnp.linspace(0, t_tot * (1+ramp), 100)\n",
    "\n",
    "    initial_states = [\n",
    "        qutip.basis(qbt.truncated_dim, 1),\n",
    "        qutip.basis(qbt.truncated_dim, 2),\n",
    "    ]\n",
    "\n",
    "    def _H(t,args):\n",
    "        _H =  qbt.diag_hamiltonian.full()\n",
    "        _H += driven_op.full() * square_pulse_with_rise_fall_jnp(t, args)\n",
    "        return _H \n",
    "    f = functools.partial(_H, args = {\n",
    "                                    \"w_d\": w_d,    # No extra 2pi factor\n",
    "                                    \"amp\": amp,    # No extra 2pi factor\n",
    "                                    \"t_square\": t_tot * (1-ramp),\n",
    "                                    \"t_rise\": t_tot * ramp,\n",
    "                                })\n",
    "    H =  dq.timecallable(f)\n",
    "\n",
    "    results = dq.sesolve(\n",
    "                    H = H,\n",
    "                    psi0 = initial_states,\n",
    "                    tsave = tlist,\n",
    "                    exp_ops = e_ops,\n",
    "                    solver = solver,\n",
    "                    options=dq.Options(progress_meter = None),\n",
    "                    )\n",
    "    one_minus_pop2 = abs((1 - results.expects[0][2][-1]).real)  # from state |1> to |2>\n",
    "    one_minus_pop1 = abs((1 - results.expects[1][1][-1]).real)  # from state |2> to |1>\n",
    "\n",
    "    return one_minus_pop2 + one_minus_pop1\n",
    "\n",
    "def optimize_for_t_tot(t_tot):\n",
    "    def dq_objective(x):\n",
    "        amp, w_d, ramp = x\n",
    "        return objective(t_tot=t_tot, amp=amp, w_d=w_d, ramp=ramp)\n",
    "    \n",
    "    amp_guess = 50/t_tot * 22\n",
    "\n",
    "    func = jax.value_and_grad(dq_objective)\n",
    "\n",
    "    file_name = f\"nevergrad_optimized_results_{t_tot}.pkl\"\n",
    "    if os.path.exists(file_name):\n",
    "        pass\n",
    "    else:\n",
    "        file_name = f\"nevergrad_optimized_results_{int(t_tot)}.pkl\"\n",
    "    results_dict = pickle.load(open(file_name, \"rb\"))\n",
    "    params = jnp.array([results_dict[\"best_amp\"], results_dict[\"best_w_d\"], results_dict[\"best_ramp\"]]) \n",
    "\n",
    "    val = objective(t_tot=t_tot, amp=params[0], w_d=params[1], ramp=params[2])\n",
    "    print(f\"cost: {val}, t_tot: {t_tot}, amp: {params[0]}, w_d: {params[1]}, ramp: {params[2]}\")\n",
    "\n",
    "    optimizer = optax.nadam(learning_rate=jnp.array([1e-3, 1e-4, 1e-3])) \n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    num_steps = 1000\n",
    "    for step in range(num_steps):\n",
    "        print(f\"iter: {step}, params: {params}\")\n",
    "        val, grads = func(params)\n",
    "        print(f\"\\t val={val} grads: {grads}\")\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "    print(f'Optimized params for t_tot={t_tot}: {params}')\n",
    "    \n",
    "    # Extract best values\n",
    "    best_amp = params[0]\n",
    "    best_w_d = params[1]\n",
    "    best_ramp = params[2]\n",
    "    best_cost = val\n",
    "\n",
    "    # Store results in a pickle\n",
    "    results_dict = {\n",
    "        \"best_cost\": best_cost,\n",
    "        \"best_amp\": best_amp,\n",
    "        \"best_w_d\": best_w_d,\n",
    "        \"best_ramp\": best_ramp,\n",
    "    }\n",
    "\n",
    "    with open(f\"dq_optimized_results_{t_tot}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results_dict, f)\n",
    "    \n",
    "    return t_tot, results_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t_tot_list = np.linspace(50, 250, 21)\n",
    "    \n",
    "    # # Use all available CPU cores except one\n",
    "    # num_processes = max(1, mp.cpu_count() - 1)\n",
    "    num_processes = 1 # minimal example\n",
    "    # Run optimizations in parallel\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(optimize_for_t_tot, t_tot_list)\n",
    "    \n",
    "    # Collect and print all results\n",
    "    for t_tot, result in sorted(results):\n",
    "        print(f\"\\nResults for t_tot={t_tot}:\")\n",
    "        print(f\"Best cost: {result['best_cost']}\")\n",
    "        print(f\"Best parameters: amp={result['best_amp']}, w_d={result['best_w_d']}, ramp={result['best_ramp']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamiqs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
